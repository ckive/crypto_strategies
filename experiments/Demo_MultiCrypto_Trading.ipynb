{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/Demo_MultiCrypto_Trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl3liTlqF2tZ"
   },
   "source": [
    "# Multiple Cryptocurrencies Trading Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph-kT4laFy5k"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfKfNSTnEqsq",
    "outputId": "8bf767b8-a7c8-4a48-d825-53714dae536a"
   },
   "outputs": [],
   "source": [
    "%cd /\n",
    "!git clone https://github.com/AI4Finance-Foundation/FinRL-Meta\n",
    "%cd /FinRL-Meta/\n",
    "!pip install git+https://github.com/AI4Finance-LLC/ElegantRL.git\n",
    "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
    "!pip install yfinance stockstats\n",
    "!pip install alpaca_trade_api\n",
    "!pip install ray[default]\n",
    "!pip install lz4\n",
    "!pip install ray[tune]\n",
    "!pip install tensorboardX\n",
    "!pip install gputil\n",
    "!pip install trading_calendars\n",
    "!pip install wrds\n",
    "!pip install rqdatac\n",
    "!pip install sqlalchemy==1.2.19\n",
    "!pip install tushare\n",
    "#install talib\n",
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz \n",
    "!tar xvzf ta-lib-0.4.0-src.tar.gz\n",
    "import os\n",
    "os.chdir('ta-lib') \n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "os.chdir('../')\n",
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpUwP86TF9LE"
   },
   "source": [
    "## Import Related Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S3W6tDA_FFGA",
    "outputId": "3301dac6-f81b-4f1e-a934-886f00f86bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/FinRL-Meta\n"
     ]
    }
   ],
   "source": [
    "%cd /FinRL-Meta/\n",
    "from finrl_meta.env_crypto_trading.env_multiple_crypto import CryptoEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSDuv3R9H6Y5"
   },
   "source": [
    "## Functions for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3u8KdIcwH59J"
   },
   "outputs": [],
   "source": [
    "from drl_agents.elegantrl_models import DRLAgent as DRLAgent_erl\n",
    "from drl_agents.rllib_models import DRLAgent as DRLAgent_rllib\n",
    "from drl_agents.stablebaselines3_models import DRLAgent as DRLAgent_sb3\n",
    "from finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "def train(start_date, end_date, ticker_list, data_source, time_interval, \n",
    "          technical_indicator_list, drl_lib, env, model_name, if_vix = True,\n",
    "          **kwargs):\n",
    "    \n",
    "    #process data using unified data processor\n",
    "    DP = DataProcessor(data_source,  **kwargs)\n",
    "    price_array, tech_array, turbulence_array = DP.run(ticker_list, start_date\n",
    "                                                       , end_date, time_interval, \n",
    "                                                       technical_indicator_list, \n",
    "                                                       if_vix)\n",
    "    data_config = {'price_array':price_array,\n",
    "                   'tech_array':tech_array,\n",
    "                   'turbulence_array':turbulence_array}\n",
    "    #build environment using processed data\n",
    "    env_instance = env(config=data_config)\n",
    "\n",
    "    #read parameters and load agents\n",
    "    current_working_dir = kwargs.get('current_working_dir','./'+str(model_name))\n",
    "\n",
    "    if drl_lib == 'elegantrl':\n",
    "        break_step = kwargs.get('break_step', 1e6)\n",
    "        erl_params = kwargs.get('erl_params')\n",
    "\n",
    "        agent = DRLAgent_erl(env = env,\n",
    "                             price_array = price_array,\n",
    "                             tech_array=tech_array,\n",
    "                             turbulence_array=turbulence_array)\n",
    "        \n",
    "        model = agent.get_model(model_name, model_kwargs = erl_params)\n",
    "        trained_model = agent.train_model(model=model, \n",
    "                                          cwd=current_working_dir,\n",
    "                                          total_timesteps=break_step)\n",
    "      \n",
    "    elif drl_lib == 'rllib':\n",
    "        total_episodes = kwargs.get('total_episodes', 100)\n",
    "        rllib_params = kwargs.get('rllib_params')\n",
    "\n",
    "        agent_rllib = DRLAgent_rllib(env = env,\n",
    "                       price_array=price_array,\n",
    "                       tech_array=tech_array,\n",
    "                       turbulence_array=turbulence_array)\n",
    "\n",
    "        model,model_config = agent_rllib.get_model(model_name)\n",
    "\n",
    "        model_config['lr'] = rllib_params['lr']\n",
    "        model_config['train_batch_size'] = rllib_params['train_batch_size']\n",
    "        model_config['gamma'] = rllib_params['gamma']\n",
    "\n",
    "        trained_model = agent_rllib.train_model(model=model, \n",
    "                                          model_name=model_name,\n",
    "                                          model_config=model_config,\n",
    "                                          total_episodes=total_episodes)\n",
    "        trained_model.save(current_working_dir)\n",
    "        \n",
    "            \n",
    "    elif drl_lib == 'stable_baselines3':\n",
    "        total_timesteps = kwargs.get('total_timesteps', 1e6)\n",
    "        agent_params = kwargs.get('agent_params')\n",
    "\n",
    "        agent = DRLAgent_sb3(env = env_instance)\n",
    "\n",
    "        model = agent.get_model(model_name, model_kwargs = agent_params)\n",
    "        trained_model = agent.train_model(model=model, \n",
    "                                tb_log_name=model_name,\n",
    "                                total_timesteps=total_timesteps)\n",
    "        print('Training finished!')\n",
    "        trained_model.save(current_working_dir)\n",
    "        print('Trained model saved in ' + str(current_working_dir))\n",
    "    else:\n",
    "        raise ValueError('DRL library input is NOT supported. Please check.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4sKCkoAIegn"
   },
   "outputs": [],
   "source": [
    "# import DRL agents\n",
    "from drl_agents.stablebaselines3_models import DRLAgent as DRLAgent_sb3\n",
    "from drl_agents.rllib_models import DRLAgent as DRLAgent_rllib\n",
    "from drl_agents.elegantrl_models import DRLAgent as DRLAgent_erl\n",
    "\n",
    "# import data processor\n",
    "from finrl_meta.data_processor import DataProcessor\n",
    "\n",
    "def test(start_date, end_date, ticker_list, data_source, time_interval,\n",
    "            technical_indicator_list, drl_lib, env, model_name, if_vix=True,\n",
    "            **kwargs):\n",
    "    #process data using unified data processor\n",
    "    DP = DataProcessor(data_source,  **kwargs)\n",
    "    price_array, tech_array, turbulence_array = DP.run(ticker_list, start_date\n",
    "                              , end_date, time_interval, \n",
    "                              technical_indicator_list, \n",
    "                              if_vix)\n",
    "    np.save('./price_array.npy', price_array)\n",
    "    data_config = {'price_array':price_array,\n",
    "                   'tech_array':tech_array,\n",
    "                   'turbulence_array':turbulence_array}\n",
    "    #build environment using processed data\n",
    "    env_instance = env(config=data_config)\n",
    "\n",
    "    env_config = {\n",
    "        \"price_array\": price_array,\n",
    "        \"tech_array\": tech_array,\n",
    "        \"turbulence_array\": turbulence_array,\n",
    "        \"if_train\": False,\n",
    "    }\n",
    "    env_instance = env(config=env_config)\n",
    "\n",
    "    # load elegantrl needs state dim, action dim and net dim\n",
    "    net_dimension = kwargs.get(\"net_dimension\", 2 ** 7)\n",
    "    current_working_dir = kwargs.get(\"current_working_dir\", \"./\" + str(model_name))\n",
    "    print(\"price_array: \", len(price_array))\n",
    "\n",
    "    if drl_lib == \"elegantrl\":\n",
    "        episode_total_assets = DRLAgent_erl.DRL_prediction(\n",
    "            model_name=model_name,\n",
    "            cwd=current_working_dir,\n",
    "            net_dimension=net_dimension,\n",
    "            environment=env_instance,\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "\n",
    "    elif drl_lib == \"rllib\":\n",
    "        # load agent\n",
    "        episode_total_assets = DRLAgent_rllib.DRL_prediction(\n",
    "            model_name=model_name,\n",
    "            env=env,\n",
    "            price_array=price_array,\n",
    "            tech_array=tech_array,\n",
    "            turbulence_array=turbulence_array,\n",
    "            agent_path=current_working_dir,\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "\n",
    "    elif drl_lib == \"stable_baselines3\":\n",
    "        episode_total_assets = DRLAgent_sb3.DRL_prediction_load_from_file(\n",
    "            model_name=model_name, environment=env_instance, cwd=current_working_dir\n",
    "        )\n",
    "\n",
    "        return episode_total_assets\n",
    "    else:\n",
    "        raise ValueError(\"DRL library input is NOT supported. Please check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWLiSsz3Imqf"
   },
   "source": [
    "## Multiple Cryptocurrencies Trading Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUTc4dhRIraO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CryptoEnv:  # custom env\n",
    "    def __init__(self, config, lookback=1, initial_capital=1e6, \n",
    "                 buy_cost_pct=1e-3, sell_cost_pct=1e-3, gamma = 0.99):\n",
    "        self.lookback = lookback\n",
    "        self.initial_total_asset = initial_capital\n",
    "        self.initial_cash = initial_capital\n",
    "        self.buy_cost_pct = buy_cost_pct\n",
    "        self.sell_cost_pct = sell_cost_pct\n",
    "        self.max_stock = 1\n",
    "        self.gamma = gamma\n",
    "        self.price_array = config['price_array']\n",
    "        self.tech_array = config['tech_array']\n",
    "        self._generate_action_normalizer()\n",
    "        self.crypto_num = self.price_array.shape[1]\n",
    "        self.max_step = self.price_array.shape[0] - lookback - 1\n",
    "        \n",
    "        # reset\n",
    "        self.time = lookback-1\n",
    "        self.cash = self.initial_cash\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time]\n",
    "        self.stocks = np.zeros(self.crypto_num, dtype=np.float32)\n",
    "\n",
    "        self.total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        self.episode_return = 0.0  \n",
    "        self.gamma_return = 0.0\n",
    "        \n",
    "\n",
    "        '''env information'''\n",
    "        self.env_name = 'MulticryptoEnv'\n",
    "        self.state_dim = 1 + (self.price_array.shape[1] + self.tech_array.shape[1])*lookback\n",
    "        self.action_dim = self.price_array.shape[1]\n",
    "        self.if_discrete = False\n",
    "        self.target_return = 10\n",
    "\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        self.time = self.lookback-1\n",
    "        self.current_price = self.price_array[self.time]\n",
    "        self.current_tech = self.tech_array[self.time]\n",
    "        self.cash = self.initial_cash  # reset()\n",
    "        self.stocks = np.zeros(self.crypto_num, dtype=np.float32)\n",
    "        self.total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        \n",
    "        state = self.get_state()\n",
    "        return state\n",
    "\n",
    "    def step(self, actions) -> (np.ndarray, float, bool, None):\n",
    "        self.time += 1\n",
    "        \n",
    "        price = self.price_array[self.time]\n",
    "        for i in range(self.action_dim):\n",
    "            norm_vector_i = self.action_norm_vector[i]\n",
    "            actions[i] = actions[i] * norm_vector_i\n",
    "            \n",
    "        for index in np.where(actions < 0)[0]:  # sell_index:\n",
    "            if price[index] > 0:  # Sell only if current asset is > 0\n",
    "                sell_num_shares = min(self.stocks[index], -actions[index])\n",
    "                self.stocks[index] -= sell_num_shares\n",
    "                self.cash += price[index] * sell_num_shares * (1 - self.sell_cost_pct)\n",
    "                \n",
    "        for index in np.where(actions > 0)[0]:  # buy_index:\n",
    "            if price[index] > 0:  # Buy only if the price is > 0 (no missing data in this particular date)\n",
    "                buy_num_shares = min(self.cash // price[index], actions[index])\n",
    "                self.stocks[index] += buy_num_shares\n",
    "                self.cash -= price[index] * buy_num_shares * (1 + self.buy_cost_pct)\n",
    "\n",
    "        \"\"\"update time\"\"\"\n",
    "        done = self.time == self.max_step\n",
    "        state = self.get_state()\n",
    "        next_total_asset = self.cash + (self.stocks * self.price_array[self.time]).sum()\n",
    "        reward = (next_total_asset - self.total_asset) * 2 ** -16  \n",
    "        self.total_asset = next_total_asset\n",
    "        self.gamma_return = self.gamma_return * self.gamma + reward \n",
    "        self.cumu_return = self.total_asset / self.initial_cash\n",
    "        if done:\n",
    "            reward = self.gamma_return\n",
    "            self.episode_return = self.total_asset / self.initial_cash\n",
    "        return state, reward, done, None\n",
    "\n",
    "    def get_state(self):\n",
    "        state =  np.hstack((self.cash * 2 ** -18, self.stocks * 2 ** -3))\n",
    "        for i in range(self.lookback):\n",
    "            tech_i = self.tech_array[self.time-i]\n",
    "            normalized_tech_i = tech_i * 2 ** -15\n",
    "            state = np.hstack((state, normalized_tech_i)).astype(np.float32)\n",
    "        return state\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def _generate_action_normalizer(self):\n",
    "        action_norm_vector = []\n",
    "        price_0 = self.price_array[0]\n",
    "        for price in price_0:\n",
    "            x = math.floor(math.log(price, 10)) #the order of magnitude \n",
    "            action_norm_vector.append(1/((10)**x)) \n",
    "            \n",
    "        action_norm_vector = np.asarray(action_norm_vector) * 10000\n",
    "        self.action_norm_vector = np.asarray(action_norm_vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8YsfqhOGBaf"
   },
   "source": [
    "## Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2uDrp5uFM3t"
   },
   "outputs": [],
   "source": [
    "TICKER_LIST = ['BTCUSDT','ETHUSDT','ADAUSDT','BNBUSDT','XRPUSDT','SOLUSDT','DOTUSDT',\n",
    "         'DOGEUSDT','AVAXUSDT','UNIUSDT']\n",
    "env = CryptoEnv\n",
    "TRAIN_START_DATE = '2021-09-01'\n",
    "TRAIN_END_DATE = '2021-09-20'\n",
    "\n",
    "TEST_START_DATE = '2021-09-21'\n",
    "TEST_END_DATE = '2021-09-30'\n",
    "TECHNICAL_INDICATORS_LIST = ['macd','rsi','cci','dx'] #self-defined technical indicator list is NOT supported yet\n",
    "\n",
    "ERL_PARAMS = {\"learning_rate\": 2 ** -15,\"batch_size\": 2**11,\"gamma\":  0.99,\n",
    "              \"seed\":312,\"net_dimension\": 2**9, \"target_step\": 5000, \n",
    "              \"eval_time_gap\": 30, \"eval_times\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFar1DpfGFvP"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "Hwt2kM5pFPiK",
    "outputId": "b9533080-a16e-400e-989e-adc6de71007e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binance successfully connected\n",
      "Succesfully add technical indicators\n",
      "| Arguments Remove cwd: ./test_ppo\n",
      "################################################################################\n",
      "ID     Step    maxR |    avgR   stdR   avgS  stdS |    expR   objC   etc.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-29348b501caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0merl_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mERL_PARAMS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mbreak_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mif_vix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       )\n",
      "\u001b[0;32m<ipython-input-3-a440fe771f96>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(start_date, end_date, ticker_list, data_source, time_interval, technical_indicator_list, drl_lib, env, model_name, if_vix, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         trained_model = agent.train_model(model=model, \n\u001b[1;32m     36\u001b[0m                                           \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_working_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                                           total_timesteps=break_step)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdrl_lib\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'rllib'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/FinRL-Meta/drl_agents/elegantrl_models.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, model, cwd, total_timesteps)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/elegantrl/train/run.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mlogging_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_update_tau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/elegantrl/agents/AgentPPO.py\u001b[0m in \u001b[0;36mupdate_net\u001b[0;34m(self, buffer, batch_size, repeat_times, soft_update_tau)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mbuf_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_old_logprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mbuf_r_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_adv_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reward_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# detach()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mbuf_adv_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuf_adv_v\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbuf_adv_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_a_value\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbuf_adv_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;31m# buf_adv_v: buffer data of adv_v value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/elegantrl/agents/AgentPPO.py\u001b[0m in \u001b[0;36mget_reward_sum_raw\u001b[0;34m(self, buf_len, buf_reward, buf_mask, buf_value)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mpre_r_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mbuf_r_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpre_r_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m             \u001b[0mpre_r_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf_r_sum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mbuf_adv_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf_r_sum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbuf_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8641 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "train(start_date = TRAIN_START_DATE, \n",
    "      end_date = TRAIN_END_DATE,\n",
    "      ticker_list = TICKER_LIST, \n",
    "      data_source = 'binance',\n",
    "      time_interval= '5m', \n",
    "      technical_indicator_list= TECHNICAL_INDICATORS_LIST,\n",
    "      drl_lib='elegantrl', \n",
    "      env=env, \n",
    "      model_name='ppo', \n",
    "      current_working_dir='./test_ppo',\n",
    "      erl_params=ERL_PARAMS,\n",
    "      break_step=5e4,\n",
    "      if_vix=False\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y7bIQdkGLLU"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44EXeZglFS8d"
   },
   "outputs": [],
   "source": [
    "account_value_erl = test(start_date = TEST_START_DATE, \n",
    "                        end_date = TEST_END_DATE,\n",
    "                        ticker_list = TICKER_LIST, \n",
    "                        data_source = 'binance',\n",
    "                        time_interval= '5m', \n",
    "                        technical_indicator_list= TECHNICAL_INDICATORS_LIST,\n",
    "                        drl_lib='elegantrl', \n",
    "                        env=env, \n",
    "                        model_name='ppo', \n",
    "                        current_working_dir='./test_ppo', \n",
    "                        net_dimension = 2**9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSQ8YMCZGN1H"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fInPrpp6QoKK"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "#calculate agent returns\n",
    "account_value_erl = np.array(account_value_erl)\n",
    "agent_returns = account_value_erl/account_value_erl[0]\n",
    "#calculate buy-and-hold btc returns\n",
    "price_array = np.load('./price_array.npy')\n",
    "btc_prices = price_array[:,0]\n",
    "buy_hold_btc_returns = btc_prices/btc_prices[0]\n",
    "#calculate equal weight portfolio returns\n",
    "price_array = np.load('./price_array.npy')\n",
    "initial_prices = price_array[0,:]\n",
    "equal_weight = np.array([1e5/initial_prices[i] for i in range(10)])\n",
    "equal_weight_values = []\n",
    "for i in range(0, price_array.shape[0]):\n",
    "  equal_weight_values.append(np.sum(equal_weight * price_array[i]))\n",
    "equal_weight_values = np.array(equal_weight_values)\n",
    "equal_returns = equal_weight_values/equal_weight_values[0]\n",
    "#plot \n",
    "plt.figure(dpi=200)\n",
    "plt.grid()\n",
    "plt.grid(which='minor', axis='y')\n",
    "plt.title('Cryptocurrency Trading ', fontsize=20)\n",
    "plt.plot(agent_returns, label = 'ElegantRL Agent', color = 'red')\n",
    "plt.plot(buy_hold_btc_returns, label = 'Buy-and-Hold BTC', color = 'blue')\n",
    "plt.plot(equal_returns, label = 'Equal Weight Portfolio', color = 'green')\n",
    "plt.ylabel('Return', fontsize=16)\n",
    "plt.xlabel('Times (5min)', fontsize=16)\n",
    "plt.xticks(size = 14)\n",
    "plt.yticks(size = 14)\n",
    "'''ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(210))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(21))\n",
    "ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.005))\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1, decimals=2))\n",
    "ax.xaxis.set_major_formatter(ticker.FixedFormatter([]))'''\n",
    "plt.legend(fontsize=10.5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Demo_MultiCrypto_Trading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml38",
   "language": "python",
   "name": "ml38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
